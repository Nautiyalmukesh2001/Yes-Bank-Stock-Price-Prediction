{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nautiyalmukesh2001/Yes-Bank-Stock-Price-Prediction/blob/main/Yes_Bank_Stock_Price%7CPredict%7CM6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HhpQbASx8Lt"
      },
      "source": [
        "# **Project Name : Yes Bank Stock Closing Price Prediction**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2wrwfE2yf5F"
      },
      "source": [
        "**Project Type** - Time Series Analysis\n",
        "\n",
        "**Contribution** - Individual\n",
        "\n",
        "**Team Member 1** - Mukesh Nautiyal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP1t32I1m2Ka"
      },
      "source": [
        "# **Project Summary :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DKkZxaknA28"
      },
      "source": [
        "**Project Summary: Yes Bank Stock Closing Price Prediction**  \n",
        "\n",
        "**Objective**  \n",
        "This project aimed to predict the closing stock price of Yes Bank using time series analysis and machine learning techniques. The goal was to provide actionable insights for investors and financial analysts, enabling informed decision-making and effective risk management.  \n",
        "\n",
        "**Dataset**  \n",
        "The analysis was conducted using historical Yes Bank stock prices, including daily open, high, low, and close values.  \n",
        "\n",
        "**Methodology**  \n",
        "\n",
        "1. **Data Preprocessing & Wrangling** – Cleaned and prepared the dataset to ensure accuracy and consistency.  \n",
        "2. **Exploratory Data Analysis (EDA)** – Used visualizations to identify historical trends, volatility, and key patterns.  \n",
        "3. **Feature Engineering** – Created lagged features and relevant variables to enhance model performance.  \n",
        "4. **Model Implementation** – Developed and evaluated various models, including:  \n",
        "   - **Time Series Models:** ARIMA, SARIMA (to capture trends and seasonality).  \n",
        "   - **Machine Learning Models:** Linear Regression, Lasso, and Ridge (to leverage predictive patterns).  \n",
        "5. **Model Evaluation** – Assessed model performance using Mean Squared Error (MSE) and R-squared metrics.  \n",
        "\n",
        "**Key Findings**  \n",
        "\n",
        "- **ARIMA & SARIMA Models** effectively captured trends and seasonality, producing reasonable forecasts.  \n",
        "- **Machine Learning Models (Lasso & Ridge)** emphasized the significance of feature selection and regularization for better predictions.  \n",
        "- **Data Limitations**: The predictions were constrained by the dataset, which lacked external economic factors, market sentiment, and global indicators that significantly impact stock prices.  \n",
        "\n",
        "**Business Impact & Solutions**  \n",
        "\n",
        "1. **Risk Management** – Helps investors assess potential price fluctuations, enabling proactive risk mitigation.  \n",
        "2. **Investment Strategies** – Supports data-driven investment decisions by forecasting future price movements.  \n",
        "3. **Market Analysis** – Provides deeper insights into stock behavior, which can be correlated with external financial and economic conditions.  \n",
        "\n",
        "**Conclusion**  \n",
        "This project demonstrated the power of data-driven approaches in stock price prediction. While stock markets remain inherently unpredictable, the developed models offer valuable insights for investment and risk management. Future work can enhance accuracy by integrating external factors such as economic indicators, market sentiment analysis, and advanced deep learning techniques.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GitHub Link -**"
      ],
      "metadata": {
        "id": "U-d3V-eL_Wdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UpyGT76m_dvE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1onkWMOEzFrr"
      },
      "source": [
        "# **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXYuzGbZ1Q-0"
      },
      "source": [
        "**BUSINESS PROBLEM OVERVIEW**\n",
        "\n",
        "Stock market fluctuations present a significant challenge for investors and financial institutions. Predicting stock prices accurately can help in making informed investment decisions, mitigating risks, and optimizing portfolio strategies.\n",
        "\n",
        "This project focuses on predicting the closing stock price of Yes Bank using machine learning techniques. By analyzing historical stock price data, including factors such as opening price, trading volume, and market trends, this model aims to provide insights into future price movements. The outcome of this prediction can assist traders, investors, and financial analysts in making data-driven decisions, thereby improving risk assessment and investment strategies.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-it-n5PJ6qG"
      },
      "source": [
        "#**1. Dataset Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ns8Q61C_s2z"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3xjfFECJ_ky"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import plotly.express as ps\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSOfVftkAH-j"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YX4j7iOiY-"
      },
      "outputs": [],
      "source": [
        "# Creating file path\n",
        "filepath = '/content/data_YesBank_StockPrices.csv'\n",
        "\n",
        "# creating a pandas dataframe\n",
        "stock_df = pd.read_csv(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkwsoU7nC-Nm"
      },
      "source": [
        "## Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck8iuZetFU1v"
      },
      "outputs": [],
      "source": [
        "# top 5 rows of the data\n",
        "stock_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9FyBDCaFJDR"
      },
      "source": [
        "## Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDOrSdtVFyD7"
      },
      "outputs": [],
      "source": [
        "# Dataset rows and columns\n",
        "stock_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyuM8qpgFme7"
      },
      "source": [
        "## Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5865qEhxsg_"
      },
      "outputs": [],
      "source": [
        "# dataset info\n",
        "stock_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqyWzEfDGV7Q"
      },
      "source": [
        "### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caTGt3KWOKKP"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "len(stock_df[stock_df.duplicated()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb2Z6YIoN_X2"
      },
      "source": [
        "### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usKd6eLtGgAB"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "print(stock_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCD3K8xQP4UV"
      },
      "outputs": [],
      "source": [
        "# Checking Null Value by plotting Heatmap\n",
        "\n",
        "sns.heatmap(stock_df.isnull(),cbar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIx8S-jFTq7n"
      },
      "source": [
        "## What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P16jLDgJTzcB"
      },
      "source": [
        "The dataset originates from the stock market domain, specifically focusing on Yes Bank's stock prices, with the objective of predicting closing stock prices. By leveraging historical trends, this dataset aims to provide insights into market fluctuations, assisting investors and analysts in making informed decisions.\n",
        "\n",
        "It comprises 185 rows and 5 columns, capturing essential stock-related metrics. The dataset is clean and well-structured, with no missing or null values, ensuring a robust foundation for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRJMlTtuUfoI"
      },
      "source": [
        "# **2. Understanding Variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzICPjk8Uv7j"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "\n",
        "stock_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24B77WDdU3do"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "\n",
        "stock_df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYazKbl2SE2f"
      },
      "source": [
        "## Variable Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkLmndjOchbW"
      },
      "source": [
        "\n",
        "\n",
        "*   Date: Date of the Record\n",
        "*   Open: Opening Price\n",
        "*   High: Highest Price in the day\n",
        "*   Low: Lowest Price in the day\n",
        "*   Close: Closing Price in the day\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyxn48GxVTcJ"
      },
      "source": [
        "##  Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RafhT8hVYfv"
      },
      "outputs": [],
      "source": [
        "# number of unique values\n",
        "stock_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdH9uaKxSLa8"
      },
      "source": [
        "# **3. Data Wrangling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhTJPn8dX3TE"
      },
      "source": [
        "## Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__9WuEKrSN87"
      },
      "outputs": [],
      "source": [
        "# creating copy of dataset\n",
        "stock_df_copy = stock_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the date column is not structured so making it useful for analysis and setting month end date to each month\n",
        "stock_df['Date'] = pd.to_datetime(stock_df['Date'],format='%b-%y') + pd.offsets.MonthEnd(0)\n",
        "stock_df['Date'] = stock_df['Date'].dt.normalize()  # removing the timestamp\n",
        "stock_df['Day'] = stock_df['Date'].dt.day # extracting the date part\n",
        "stock_df['Month'] = stock_df['Date'].dt.month # extracting the month part\n",
        "stock_df['Year'] = stock_df['Date'].dt.year  # extracting the year part\n"
      ],
      "metadata": {
        "id": "DV6XIGTXGzS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new df with date column as index\n",
        "stock_df = stock_df.set_index('Date')"
      ],
      "metadata": {
        "id": "3Vl68lK1VtpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a group by on year to see the trend in stock prices\n",
        "stock_df.groupby('Year').mean()"
      ],
      "metadata": {
        "id": "AFTKhuWRMTUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MGHhShdfCpS"
      },
      "source": [
        "## What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDG9U1wQxW4x"
      },
      "source": [
        "To ensure data integrity and facilitate accurate analysis, I first created a copy of the original dataset to prevent any data loss during transformations. This allowed me to experiment with different data wrangling techniques without affecting the raw data.\n",
        "\n",
        "One of the key transformations involved structuring the date column to ensure consistency in the format. To enable better trend analysis, I extracted separate Year, Month, and Day columns from the date field. This decomposition made it easier to analyze stock price movements over different time periods and identify patterns at various granular levels.\n",
        "\n",
        "To understand the overall trend of Yes Bank’s stock prices, I used the groupby function to aggregate the data by year. This helped in observing how the opening price, closing price, highest price, and lowest price changed over time. By summarizing the stock price trends annually, I could identify key fluctuations and patterns in the market.\n",
        "\n",
        "From the initial insights, the grouped data revealed noticeable variations in the closing stock prices across different years. Some years exhibited significant spikes or drops, suggesting potential market events that influenced Yes Bank’s stock performance. This structured approach to data wrangling not only cleaned and organized the dataset but also provided a strong foundation for deeper time-series analysis, including identifying seasonal trends and volatility patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Q61KPmXuuJ"
      },
      "source": [
        "# **4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqcaaCb2KOyV"
      },
      "source": [
        "## Chart 1: Line Chart\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a line chart to visualize the closing price\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stock_df.index, stock_df['Close'], label='Closing Price', color='blue')\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Closing Price\")\n",
        "plt.title(\"Closing Stock Price Over Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qP8-KfsdY65x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "Nh3oXc0eoPKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line chart was chosen because it effectively visualizes the historical trend of the closing stock price over time. It allows us to observe patterns, trends, and fluctuations in the stock price, which is crucial for understanding past performance and making future predictions."
      ],
      "metadata": {
        "id": "mUuZRtYYoZcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "vkgMS00noPGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before 2018 the stock price showed a gradual increase from 2005 to 2018, indicating a positive trend.\n",
        "In 2018-2019 there was a significant surge in stock price, followed by extreme fluctuations.\n",
        "Post-2019 the stock collapsed sharply after 2019, reaching levels lower than in previous years.\n",
        "There is a horizontal line on the left side, which might indicate a data processing issue or missing values in the dataset."
      ],
      "metadata": {
        "id": "gxKf3Z2WonX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "h7iSWs9moPCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Risk Management: Understanding the sharp decline can help businesses assess risks in stock investments.\n",
        "*   Investment Strategies: Identifying cyclical patterns and volatility can help traders make informed decisions.\n",
        "*   Market Analysis: Businesses can correlate stock performance with company events, policies, or market conditions to enhance decision-making.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gLsjf9P9pB2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chart 2: Seasonal Decompose"
      ],
      "metadata": {
        "id": "toNK4V0Rp2vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform seasonal decomposition\n",
        "result = seasonal_decompose(stock_df['Close'], model='additive', period=12)"
      ],
      "metadata": {
        "id": "Y6_5BO0FotPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot trend\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(412)\n",
        "plt.plot(result.trend, label='Trend')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hB7csR5poqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot seasonality\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(413)\n",
        "plt.plot(result.seasonal, label='Seasonality')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pY-twckcpsNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot residuals\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(414)\n",
        "plt.plot(result.resid, label='Residuals')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fczcXsGdpzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chart 3: Box Plot"
      ],
      "metadata": {
        "id": "RJ_O8dvFqDd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a boxplot to visualize the features of prices\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(data=stock_df['Close'])\n",
        "plt.title(\"Stock Price Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFkTGPjedDaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chart 4: Distribution"
      ],
      "metadata": {
        "id": "nmL5Eke2qMfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=stock_df, x=\"Close\",  kde = True, color  = 'Red') # closing price\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4fAgYW0wixNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(data=stock_df, x=\"Close\",  fill = True, color  = 'Red') # closing price\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "su1btKpXkIFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating daily returns to check stock price volatility.\n",
        "stock_df['Daily Return'] = stock_df['Close'].pct_change()\n",
        "\n",
        "# plotting\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(stock_df['Daily Return'].dropna(), bins=50, kde=True)\n",
        "plt.xlabel(\"Daily Return\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Daily Returns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tn_PXswwdJeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chart 5: Smoothed Closing Price Trend Over Time"
      ],
      "metadata": {
        "id": "RQz59viisNfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "moving_avg = stock_df['Close'].rolling(window=12).mean()  # 12 Month moving average\n",
        "\n",
        "# Plotting the original data and the moving average\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stock_df['Close'], label='Original Data')\n",
        "plt.plot(moving_avg, label='12-Month Moving Average', color='orange')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Time Series with 12-Month Moving Average')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2Do7GDM4Rxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart 6: Candle"
      ],
      "metadata": {
        "id": "3v4b-aRkrjUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Candlestick Chart for Price Movement\n",
        "# Visualize open, high, low, close (OHLC) prices.\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[go.Candlestick(\n",
        "    x=stock_df.index,\n",
        "    open=stock_df['Open'], high=stock_df['High'],\n",
        "    low=stock_df['Low'], close=stock_df['Close'])])\n",
        "\n",
        "fig.update_layout(title=\"Candlestick Chart for Yes Bank Stock\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "0a348LYGkuwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart 7: Relative Strength Index"
      ],
      "metadata": {
        "id": "pyLY8BnqrxIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relative Strength Index (RSI) – Momentum Indicator\n",
        "# RSI helps identify overbought/oversold conditions.\n",
        "\n",
        "def compute_RSI(data, window=14):\n",
        "    delta = data.diff(1)\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
        "    RS = gain / loss\n",
        "    RSI = 100 - (100 / (1 + RS))\n",
        "    return RSI\n",
        "\n",
        "stock_df['RSI'] = compute_RSI(stock_df['Close'])\n",
        "\n",
        "stock_df['RSI'].plot(title=\"Relative Strength Index (RSI)\",figsize=(15,6))\n",
        "plt.show()\n",
        "\n",
        "# RSI > 70 → Overbought (Stock may be overpriced → possible sell signal)\n",
        "# RSI < 30 → Oversold (Stock may be undervalued → possible buy signal)"
      ],
      "metadata": {
        "id": "pZfBDdwIliA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "pN9ElOVttHJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RSI chart is chosen to analyze the stock's momentum and identify overbought and oversold conditions over time. It helps in detecting trend reversals and understanding whether the stock is in a bullish or bearish phase."
      ],
      "metadata": {
        "id": "DhmDeyJxtYUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "abyEQe-utG9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RSI values above 70 indicate overbought conditions, suggesting potential price drops or corrections.\n",
        "RSI values below 30 indicate oversold conditions, signaling possible price increases or rebounds.\n",
        "The chart shows multiple peaks above 70 and dips below 30, suggesting high volatility and frequent trend changes."
      ],
      "metadata": {
        "id": "e_vaM1A_tdAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "ORBWc38CtG0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart 8: Heatmap"
      ],
      "metadata": {
        "id": "Qwo8tuIlr0Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(stock_df[['Open', 'High', 'Low', 'Close']].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TjYdEgvIdJbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chart 9: Pairplot"
      ],
      "metadata": {
        "id": "_Cihawdnr4AS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting a pairplot\n",
        "sns.pairplot(stock_df[['Open','High','Low','Close']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kZVUwzz8dJX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Hypothesis Testing"
      ],
      "metadata": {
        "id": "SvF_bdzcUe9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "kvAhNNsesEJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is stationary and have a constant mean and variance with no seasonality"
      ],
      "metadata": {
        "id": "RW6smFiVsJEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing ADF test to calculate the p-value\n",
        "# Null hypothesis = Series has a unit root\n",
        "# Alternate hypothesis = Series has no unit root\n",
        "\n",
        "result = adfuller(stock_df['Close'])\n",
        "print('p-value: {}'.format(result[1]))\n",
        "if result[1] < 0.05:\n",
        "  print(\"Strong evidence against the null hypothesis, reject the null hypothesis.Data has no unit root and is stationary\")\n",
        "else:\n",
        "  print('Weak evidence against the null hypothesis, time series has a unit root, indicating it is not stationary')"
      ],
      "metadata": {
        "id": "10FU-O0hmPt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "LYCgEBWstapm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stock Returns Follow a Normal Distribution"
      ],
      "metadata": {
        "id": "gPLemD49tevm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Shapiro-Wilk Test\n",
        "# Null Hypothesis = Stock returns follow normal distribution\n",
        "# Alternate Hypothesis = Stock returns do not follow normal distribution\n",
        "\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stock_returns = stock_df['Close'].pct_change().dropna()\n",
        "shapiro_stat, shapiro_p = shapiro(stock_returns)\n",
        "\n",
        "print(f'Shapiro-Wilk Statistic: {shapiro_stat}, p-value: {shapiro_p}')\n",
        "if shapiro_p < 0.05:\n",
        "    print(\"Reject null hypothesis: Stock returns are not normally distributed.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: Stock returns follow a normal distribution.\")"
      ],
      "metadata": {
        "id": "svbfrBxXmPp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "8BsrCbvevR6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " If past stock prices influence future prices"
      ],
      "metadata": {
        "id": "M6O1mx6PvYoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Autocorrelation Test - Ljung-Box Test\n",
        "# Null hypothesis = No autocorrelation in stock returns (efficient market).\n",
        "# Alternate hypothesis = Stock returns show autocorrelation (inefficient market).\n",
        "\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "lb_test = acorr_ljungbox(stock_returns, lags=[10], return_df=True)\n",
        "print(lb_test)\n",
        "\n",
        "if lb_test['lb_pvalue'].values[0] < 0.05:\n",
        "    print(\"Reject null hypothesis: Stock returns exhibit autocorrelation (potential inefficiency).\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant autocorrelation (efficient market).\")\n"
      ],
      "metadata": {
        "id": "vICLqMd8vOln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Feature Engineering & Data Pre-processing"
      ],
      "metadata": {
        "id": "uwXYREELmQVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to check data is stationary or not\n",
        "def adf_test(series):\n",
        "    result = adfuller(series)\n",
        "    print('ADF Statistics : {}'.format(result[0]))\n",
        "    print('p-value: {}'.format(result[1]))\n",
        "    if result[1] < 0.05:\n",
        "        print(\"Strong evidence against the null hypothesis, reject the null hypothesis.Data has no unit root and is stationary\")\n",
        "    else:\n",
        "        print('Weak evidence against the null hypothesis, time series has a unit root, indicating it is not stationary')"
      ],
      "metadata": {
        "id": "sFdu_YzH5k91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adf test for closing price\n",
        "adf_test(stock_df['Close'])"
      ],
      "metadata": {
        "id": "yiC9nAMMFLM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first differencing\n",
        "stock_df['First_Differencing'] = stock_df['Close'].diff()"
      ],
      "metadata": {
        "id": "0z0D2Hliqhuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adf test after first differencing\n",
        "adf_test(stock_df['First_Differencing'].dropna())"
      ],
      "metadata": {
        "id": "gIvdWtyF54AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# second differencing\n",
        "stock_df['Second_Differencing'] = stock_df['First_Differencing'].diff()"
      ],
      "metadata": {
        "id": "SRV6-LWQ6CF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adf test after second differencing\n",
        "adf_test(stock_df['Second_Differencing'].dropna())"
      ],
      "metadata": {
        "id": "EzfTZD276K0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the original and differenced data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(stock_df['Close'], label='Original Closing Price')\n",
        "plt.legend(loc='upper left')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(stock_df['Second_Differencing'].dropna(), label='Second Differencing', color='orange')\n",
        "plt.legend(loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H8U0ycpY6jMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting a acf plot to determine the q value for the arima model\n",
        "acf_plot = plot_acf(stock_df['Second_Differencing'].dropna())"
      ],
      "metadata": {
        "id": "pmpDfUh265BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting pacf plot to determine the p value\n",
        "pacf_plot = plot_pacf(stock_df['Second_Differencing'].dropna())"
      ],
      "metadata": {
        "id": "0akuhfAZqx2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. ML Model Implementation"
      ],
      "metadata": {
        "id": "2OdB9oP4nIe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting train and test data\n",
        "train = stock_df['Close'].iloc[:-12]\n",
        "test = stock_df['Close'].iloc[-12:]\n",
        "\n",
        "# creating model\n",
        "arima_model = ARIMA(train, order=(12, 2,8))\n",
        "\n",
        "# model fit\n",
        "arima_result = arima_model.fit()\n",
        "\n",
        "# prediction for test data\n",
        "arima_forecast = arima_result.forecast(steps=12)"
      ],
      "metadata": {
        "id": "yEgzhDqhxzFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the models on test data\n",
        "arima_mse = mean_squared_error(test, arima_forecast)\n",
        "\n",
        "arima_mse"
      ],
      "metadata": {
        "id": "AgMkJlMbxzC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of arima model\n",
        "arima_result.summary()"
      ],
      "metadata": {
        "id": "TQK-pRJE-sME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making prediction for all values\n",
        "stock_df['pred_arima']  = arima_result.predict(start = datetime(2005,7,31), end=datetime(2020,11,30))"
      ],
      "metadata": {
        "id": "vD8gtf8Ke0Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating mean residuals between actual and predicted values\n",
        "sum(abs(stock_df['Close'] - stock_df['pred_arima']))/len(stock_df['Close'])"
      ],
      "metadata": {
        "id": "WEfe1Z21ju9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the graph to visualize the predicted values over actual values\n",
        "stock_df[['Close','pred_arima']].plot(figsize=(12,6))"
      ],
      "metadata": {
        "id": "P9eq1LenfV1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying SARIMA model\n",
        "sarima_model = SARIMAX(train, order=(12, 0, 8), seasonal_order=(0, 1, 0, 12))\n",
        "\n",
        "# model fit sarima\n",
        "sarima_result = sarima_model.fit()\n",
        "\n",
        "# sarima predictions\n",
        "sarima_forecast = sarima_result.forecast(steps=12)"
      ],
      "metadata": {
        "id": "3eYzgoFxxzAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the sarima model on test data\n",
        "sarima_mse = mean_squared_error(test, sarima_forecast)\n",
        "\n",
        "sarima_mse"
      ],
      "metadata": {
        "id": "DGkVkKV8xy-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting all values using sarima model\n",
        "stock_df['pred_sarima']  = arima_result.predict(datetime(2005,7,31), end=datetime(2020,11,30))"
      ],
      "metadata": {
        "id": "pqU-2H4bFJJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating mean residuals by sarima model\n",
        "sum(abs(stock_df['Close'] - stock_df['pred_sarima']))/len(stock_df['Close'])"
      ],
      "metadata": {
        "id": "jiDUl7-jmcmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting sarima's predicted and actual values\n",
        "stock_df[['Close','pred_sarima']].plot(figsize=(12,6))"
      ],
      "metadata": {
        "id": "APKLihwkFzG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating new column storing previous day closing price (lag 1)\n",
        "stock_df['Lag1'] = stock_df['Close'].shift(1)\n",
        "\n",
        "# removing null\n",
        "stock_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "XFBP_qBKvVmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data for regression model\n",
        "X = stock_df[['Lag1']]\n",
        "y = stock_df['Close']"
      ],
      "metadata": {
        "id": "9RzISrglDxT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Tt1tA3w9xy6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression model\n",
        "model_lr = LinearRegression()\n",
        "\n",
        "# model fit\n",
        "model_lr.fit(X_train,y_train)\n",
        "\n",
        "# model prediction\n",
        "y_pred_lr = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "iQyJMbxGxy3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mse = mean_squared_error(y_test, y_pred_lr)\n",
        "r2 = r2_score(y_test,y_pred_lr)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print('r2 score is ',r2)"
      ],
      "metadata": {
        "id": "o7VaFiLpxy1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Lasso regression model\n",
        "lasso = Lasso(alpha=1.0)  # alpha is the regularization parameter\n",
        "\n",
        "# Train the model\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "r2_lasso = r2_score(y_test,y_pred_lasso)\n",
        "print(f\"Lasso Regression Mean Squared Error: {mse_lasso}\")\n",
        "print(f\"Lasso Regression r2 score: {r2_lasso:.2f}\")"
      ],
      "metadata": {
        "id": "9Se-NF7Txywi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Ridge regression model\n",
        "ridge = Ridge(alpha=1.0)  # alpha is the regularization parameter\n",
        "\n",
        "# Train the model\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test,y_pred_ridge)\n",
        "print(f\"Ridge Regression Mean Squared Error: {mse_ridge}\")\n",
        "print(f\"Ridge Regression r2 score: {r2_ridge:.2f}\")"
      ],
      "metadata": {
        "id": "HvSPXXXkxyuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion"
      ],
      "metadata": {
        "id": "biH8-DrZnSIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Accurate Stock Price Forecasting: Applied time series analysis (ARIMA, SARIMA) and machine learning models (Lasso, Ridge) to predict Yes Bank’s closing stock price, providing reasonable forecasts based on historical data.\n",
        "\n",
        "2. Risk Management & Investment Strategies: Predictive models assist investors in assessing potential price fluctuations, helping in portfolio optimization and risk mitigation.\n",
        "\n",
        "3. Market Analysis & Decision-Making: The insights gained enable financial analysts to better understand stock trends, supporting strategic market decisions.\n",
        "\n",
        "4. Challenges & Limitations: The models relied solely on historical stock prices and did not incorporate external economic indicators, market news, or sentiment analysis, which could impact prediction accuracy.\n",
        "\n",
        "5. Future Enhancements: Incorporating macroeconomic factors, company financials, and real-time news sentiment could improve forecasting precision. Advanced deep learning models like LSTMs and transformers can be explored for enhanced performance.\n",
        "\n",
        "6. Business Impact: While absolute accuracy in stock price prediction is challenging due to market volatility, this project demonstrates the value of data-driven approaches in making informed financial decisions and reducing investment risks."
      ],
      "metadata": {
        "id": "Q94JG8JaysfM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9HhpQbASx8Lt",
        "TP1t32I1m2Ka",
        "U-d3V-eL_Wdz",
        "1onkWMOEzFrr",
        "7Ns8Q61C_s2z",
        "7MGHhShdfCpS",
        "l9Q61KPmXuuJ",
        "VqcaaCb2KOyV",
        "Nh3oXc0eoPKE",
        "vkgMS00noPGR",
        "toNK4V0Rp2vi",
        "RJ_O8dvFqDd5",
        "nmL5Eke2qMfw",
        "RQz59viisNfI",
        "3v4b-aRkrjUD",
        "pyLY8BnqrxIF",
        "pN9ElOVttHJs",
        "abyEQe-utG9A",
        "ORBWc38CtG0M",
        "Qwo8tuIlr0Zv",
        "_Cihawdnr4AS"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNInmVXMOB7nDry+aZMf0QF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}